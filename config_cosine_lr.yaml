job_id_regexp: "Job Id:(\\d+)"
cmd: "sbatch {sbatch_script}"
check_interval_secs: 600
partition: booster
account: laionize
beta1: 0.9
beta2: 0.95
wd: 0.2
grad_clip_norm: 1
lr_scheduler: cosine
lr_cooldown_end: 0.0
lr_cooldown_power: 1.0
epochs_cooldown: 0
resume: latest
time_minutes: 360
experiments:
  small:
    model_scale:
        model: [ViT-B-32]
    samples_seen_scale:
        - 1.28M:
                nodes: 16
                train_num_samples: 128_000
                epochs: 10
                warmup: 10
                lr: [5e-5, 5e-4, 1e-4, 1e-3]
                batch_size: [2, 4, 8, 16, 32]
                siglip: [true, false]
        - 12.8M:
            nodes: 16
            train_num_samples: 1_280_000
            epochs: 10
            warmup: 100
            lr: [5e-4, 1e-3]
            batch_size: 64
            siglip: [true, false]
        - 128M:
            nodes: 64
            train_num_samples: 12_800_000
            epochs: 10
            warmup: 500
            lr: [5e-4, 1e-3]
            batch_size: 64
            siglip: [true, false]
        - 1.28B:
            nodes: 64
            train_num_samples: 128_000_000
            epochs: 10
            warmup: 500
            lr: [5e-4, 1e-3]
            batch_size: 354
            siglip: [true, false]
        - 3B:
            nodes: 128
            train_num_samples: 100_000_000
            epochs: 30
            warmup: 500
            lr: [1.5e-3]
            batch_size: 354
            siglip: [true, false]
        - 12.8B:
            nodes: 128
            train_num_samples: 128_000_000
            epochs: 100
            warmup: 1000
            lr: [1.5e-3]
            batch_size: 354
            siglip: [true, false]
        - 34B:
            nodes: 128
            train_num_samples: 340_000_000
            epochs: 100
            warmup: 2000
            lr: [1.5e-3]
            batch_size: 354
            siglip: [true, false]
mode:
  - train:
      template: train.sbatch
      sbatch_script: "sbatch_scripts/cosine_lr/{exp_name}_train.sbatch"
      output_file: "{logs}/{folder_name}/slurm_train.out"
      # terminate training if we detect that last epoch is finished
      # e.g. if number of epochs is 100 and we find the expression Train Epoch: 99 .... 100%, we return 1
      # thus terminating the job.
      termination_cmd: 'let last={epochs}-1;grep "Train Epoch: $last.*100%" {output_file}|wc -l'
  - eval:
      template: eval.sbatch
      sbatch_script: "sbatch_scripts/cosine_lr/{exp_name}_eval.sbatch"
      output_file: "{logs}/{folder_name}/slurm_eval.out"
      eval_nodes: 1
      # evals have starting condition, they are only launched if  number of checkpoints is greater than number of evaluations (json result files)
      start_condition_cmd: "nc=`ls {logs}/{folder_name}/checkpoints/epoch_[0-9]*.pt|wc -l`;ne=`ls {logs}/{folder_name}/checkpoints/*.json|wc -l`;echo $(( (nc*2-ne) > 0 ))" # imagenet + coco = 2
      # we only terminate evals when number of evals is equal to number of epochs
      termination_cmd: "ne=`ls {logs}/{folder_name}/checkpoints/*.json|wc -l`;echo $(( (ne) == {epochs}*2 ))" # num of jsons = (num epochs) * (imagenet + coco = 2)
dataset: 
    - datacomp:
        train_data: "/p/fastdata/mmlaion/datacomp/datacomp_1B/flat/{0000000..0139827}.tar"
logs: "logs"
exp_name: "{dataset}_s{samples_seen_scale}_{model}_ep{epochs}_lr{lr}_b1_{beta1}_b2_{beta2}_wd{wd}_w{warmup}_gc{grad_clip_norm}_n{nodes}_bs{batch_size}_sig{siglip}"
folder_name: "cosine_lr/{exp_name}"
name: "{exp_name}_{mode}"