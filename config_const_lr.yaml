job_id_regexp: "Job Id:(\\d+)"
cmd: "sbatch {sbatch_script}"
check_interval_secs: 600
partition: booster
account: laionize
beta1: 0.9
beta2: 0.95
wd: 0.2
time_minutes: 360
grad_clip_norm: 1
lr-scheduler: const
logs: "logs/const_lr"
experiments:
    model: [ViT-B-32]
    nodes: 64
    train_num_samples: 128_000_000  
    lr: [1e-3]
    batch_size: 354
    siglip: false
    max_epochs: 100
    warmup: 500
phase:
    - pretrain:
        lr_scheduler: const
        lr_cooldown_end: 0.0
        lr_cooldown_power: 1.0
        epochs_cooldown: 0
        folder_name: "{exp_name}"
        epochs: "{max_epochs}"
        phase_params: ""
        pretrained: ""
        resume: latest
        mode:
            - train:
                template: train.sbatch
                sbatch_script: "sbatch_scripts/const_lr/{exp_name}_train.sbatch"
                output_file: "{logs}/{exp_name}/slurm_train.out"
                termination_cmd: 'let last={epochs}-1;grep "Train Epoch: $last.*100%" {output_file}|wc -l'
            - eval:
                template: eval.sbatch
                sbatch_script: "sbatch_scripts/const_lr/{exp_name}_eval.sbatch"
                output_file: "{logs}/{exp_name}/slurm_eval.out"
                eval_nodes: 1
                start_condition_cmd: "nc=`ls {logs}/{exp_name}/checkpoints/epoch_[0-9]*.pt|wc -l`;ne=`ls {logs}/{exp_name}/checkpoints/*.json|wc -l`;echo $(( (nc*2-ne) > 0 ))" # imagenet + coco = 2
                termination_cmd: "ne=`ls {logs}/{exp_name}/checkpoints/*.json|wc -l`;echo $(( (ne) == {epochs}*2 ))" # num of jsons = (num epochs) * (imagenet + coco = 2)
    - cooldown:
        lr_scheduler: const-cooldown
        lr_cooldown_end: 0.0
        lr_cooldown_power: 1.0
        epochs_cooldown: 10
        samples_seen_scale:
            - 1.28B:
                epochs_cooldown: 2
                cooldown_checkpoint: 8
            - 3B:
                epochs_cooldown: 5
                cooldown_checkpoint: 18
            - 12.8B:
                epochs_cooldown: 25
                cooldown_checkpoint: 75
        epochs: "$(({cooldown_checkpoint}+{epochs_cooldown}))"
        #epochs: "{epochs_cooldown}"
        checkpoint: "{logs}/{exp_name}/checkpoints/epoch_{cooldown_checkpoint}.pt"
        folder_name: "{exp_name}/cooldown_s{samples_seen_scale}"
        phase_params: "{samples_seen_scale}"
        pretrained: ""
        mode:
            - train:
                template: train.sbatch     
                sbatch_script: "sbatch_scripts/const_lr/{exp_name}_cooldown_s{samples_seen_scale}_train.sbatch"
                output_file: "{logs}/{folder_name}/slurm_train.out"
                start_condition_cmd: "nc=`ls {checkpoint}|wc -l`;echo $(( (nc) > 0 ))"
                termination_cmd: 'let last=$(( {cooldown_checkpoint} + {epochs_cooldown} - 1 ));grep "Train Epoch: $last.*100%" {output_file}|wc -l'
                resume: "$(if [ -f '{logs}/{folder_name}/checkpoints/epoch_latest.pt' ]; then echo 'latest'; else echo '{checkpoint}'; fi)"
            - eval:
                template: eval.sbatch
                sbatch_script: "sbatch_scripts/const_lr/{exp_name}_cooldown_s{samples_seen_scale}_eval.sbatch"
                output_file: "{logs}/{folder_name}/slurm_eval.out"
                eval_nodes: 1
                start_condition_cmd: "nc=`ls {logs}/{folder_name}/checkpoints/epoch_[0-9]*.pt|wc -l`;ne=`ls {logs}/{folder_name}/checkpoints/*.json|wc -l`;echo $(( (nc*2-ne) > 0 ))" # imagenet + coco = 2
                termination_cmd: "ne=`ls {logs}/{folder_name}/checkpoints/*.json|wc -l`;echo $(( (ne) == {epochs_cooldown}*2 ))" # num of jsons = (num epochs) * (imagenet + coco = 2)
dataset: 
    - datacomp:
        train_data: "/p/fastdata/mmlaion/datacomp/datacomp_1B/flat/{0000000..0139827}.tar"
exp_name: "{dataset}_{model}_ep{max_epochs}_lr{lr}_b1_{beta1}_b2_{beta2}_wd{wd}_w{warmup}_gc{grad_clip_norm}_n{nodes}_bs{batch_size}_sig{siglip}"
name: "{exp_name}_{phase}{phase_params}_{mode}"